% this is the beginning of the preamble section
% the next line must always be first line of a <path.tex> document
\documentclass[10pt, letterpaper, twoside]{article}
\usepackage[utf8]{inputenc}
\usepackage[sfdefault]{noto}
\setlength{\textwidth}{6in}
\setlength{\textheight}{9in}
\setlength{\topmargin}{-1in}
\setlength{\oddsidemargin}{.25in}
\setlength{\evensidemargin}{.25in}
% this package has better control of title, author elements
\usepackage{titling}
% edit the following line for the title of the article
\title{Robotic Process Automation (RPA)}
% edit the following line for the author of the article
\author{Gilles Pilon}
\setlength{\droptitle}{-8pt}
\pretitle{\begin{flushleft}\LARGE\bfseries}
\posttitle{\par\end{flushleft}}
\preauthor{\begin{flushleft}\normalsize}
\postauthor{\end{flushleft}}
\predate{\begin{flushleft}\small}
\postdate{\end{flushleft}}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt}
\raggedbottom
% this package has better control over the date format
\usepackage{datetime2}
% edit the following line to fix the data if you do not want it automatic
\date{\today}
% this package has better control over floats
\usepackage{float}
% this package has better control over images
\usepackage{graphicx}
\graphicspath{{fot/}}
\usepackage[export]{adjustbox}
\usepackage[singlelinecheck=false,justification=justified]{caption}
% very useful for mathematics
\usepackage{amsmath, amsthm, amssymb}
% required for bibtex URLs, very useful for hyperlinks
\usepackage{url}
% required for 8 bit fonts 256 glyphs
\usepackage[T1]{fontenc}
% useful for Greek letters in text mode
\usepackage[cbgreek]{textgreek}
% to create a list of equations
\usepackage{tocloft}
\setlength{\cfttabindent}{0in}
\setlength{\cftfigindent}{0in}
% used to create tables
\usepackage{booktabs}
\usepackage{multirow}
% minted for code listings
\usepackage{minted}
% use this package for better control over quotes
\usepackage{csquotes}
\usepackage[unicode]{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=magenta,
    citecolor=green
}
% useful for the bibliography
\usepackage[style=authoryear]{biblatex}
\addbibresource{~/documents/repositories/latex/pilon_gilles_bibliography.bib}
% useful for the glossary
\usepackage[toc, acronym, nopostdot, numberedsection, record=hybrid, shortcuts=ac, abbreviations]{glossaries-extra}
\makeglossaries
\GlsXtrLoadResources[
    src={../repositories/latex/pilon_gilles_glossary.bib},
    selection={recorded and deps},
    sort=letter-nocase
]
% define theorem-like elements
% \theoremstyle{myenv}
% \theoremstyle{mytheorem}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{axiom}[theorem]{Axiom}
% \theoremstyle{mydefinition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{question}[theorem]{Question}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}
\makeatletter
\@addtoreset{theorem}{section}
\makeatother
% set no indent for lists
\usepackage{enumitem}
\setlist[itemize]{leftmargin=*}
\setlist[enumerate]{leftmargin=*}
% create a list of equations command
\newcommand{\listequationsname}{List of Equations}
\newlistof{myequations}{equ}{\listequationsname}
\newcommand{\myequations}[1]{%
\addcontentsline{equ}{myequations}{\protect\numberline{\theequation}#1}\par}
\renewcommand{\cftequtitlefont}{\normalfont\Large\bfseries}
% create a list of Greek letters command
\newcommand{\listgreekname}{List of Greek Letters}
\newlistof{mygreek}{grk}{\listgreekname}
\newcommand{\mygreek}[1]{%
\addcontentsline{grk}{mygreek}{\protect\numberline{\thegreek}#1}\par}
\renewcommand{\cftgrktitlefont}{\normalfont\Large\bfseries}
% create a list of theorems command
\newcommand{\listtheoremsname}{List of Theorems}
\newlistof{mytheorems}{thm}{\listtheoremsname}
\newcommand{\mytheorems}[1]{%
\addcontentsline{thm}{mytheorems}{\protect\numberline{\thetheorem}#1}\par}
\renewcommand{\cftthmtitlefont}{\normalfont\Large\bfseries}
% create a list of definitions command
\newcommand{\listdefinitionsname}{List of Definitions}
\newlistof{mydefinitions}{def}{\listdefinitionsname}
\newcommand{\mydefinitions}[1]{%
\addcontentsline{def}{mydefinitions}{\protect\numberline{\thedefinition}#1}\par}
\renewcommand{\cftdeftitlefont}{\normalfont\Large\bfseries}
% create a list of corollaries command
\newcommand{\listcorollariesname}{List of Corollaries}
\newlistof{mycorollaries}{cor}{\listcorollariesname}
\newcommand{\mycorollaries}[1]{%
\addcontentsline{cor}{mycorollaries}{\protect\numberline{\thecorollary}#1}\par}
\renewcommand{\cftcortitlefont}{\normalfont\Large\bfseries}
% create a list of lemmas command
\newcommand{\listlemmasname}{List of Lemmas}
\newlistof{mylemmas}{lem}{\listlemmasname}
\newcommand{\mylemmas}[1]{%
\addcontentsline{lem}{mylemmas}{\protect\numberline{\thelemma}#1}\par}
\renewcommand{\cftlemtitlefont}{\normalfont\Large\bfseries}
% create a list of propositions command
\newcommand{\listpropositionsname}{List of Propositions}
\newlistof{mypropositions}{prop}{\listpropositionsname}
\newcommand{\mypropositions}[1]{%
\addcontentsline{prop}{mypropositions}{\protect\numberline{\theproposition}#1}\par}
\renewcommand{\cftproptitlefont}{\normalfont\Large\bfseries}
% useful for epigraphs
\usepackage{epigraph}
% this is the end of the preamble section
\begin{document}
\maketitle
% section quote
\renewcommand{\epigraphflush}{flushleft}
\renewcommand{\textflush}{flushleft}
\renewcommand{\sourceflush}{flushleft}
\epigraph{Improving life one Python script at a time}{Gilles Pilon}
% section abstract
\section*{Abstract}
\Gls{rpa} uses software robots to handle repetitive computer tasks. These include things like moving data between applications, filling out forms, sending emails, handling a long list of repetitive actions within a program such as \Gls{sap} and \Gls{windowspowerbi} (\cite{windowspowerbi}), and extracting data from online applications. \glsxtrshort{rpa} interacts with different computer programs just like a human would, but much faster and more accurately. \Gls{rpa} frees up employees to focus on more complex work and improve accuracy, efficiency, and productivity. This article presents several approaches and examples of \Gls{rpa}.
% section contents
\newpage
\tableofcontents
\newpage
% section introduction
\section{Introduction}\label{sec:introduction}
\Gls{rpa} provides several benefits:
\begin{itemize}
    \item{Automation of repetitive tasks to save time and money}
    \item{Customization of specific needs}
    \item{Efficiency of a single code script to perform complex workflows}
    \item{Repeatability for consistent execution of tasls}
\end{itemize}
% python libraries for rpa
\section{Python libraries, scripts, and shell scripts for RPA}\label{sec:python_libraries_scripts_shell_scripts_for_rpa}
These are a few of many possibilities for implementing \Gls{rpa}.
\begin{itemize}
\item \hyperref[sec:pyautogui]{PyAutoGUI}
\item \hyperref[sec:shell_script]{shell script}
\item \hyperref[sec:scrapy]{Scrapy + Beautiful Soup + Requests + urllib}
\item \hyperref[sec:openpyxl_pandas]{Openpyxl + pandas}
\item \hyperref[sec:pytesseract_opencv]{Python Tesseract + OpenCV}
\end{itemize}
% subsection pyautogui
\subsection{PyAutoGUI}\label{sec:pyautogui}
\enquote{\Gls{pyautogui} lets your \Gls{python} scripts control the mouse and keyboard to automate interactions with other applications. The API is designed to be simple. \Gls{pyautogui} works on Windows, macOS, and Linux, and runs on \Gls{python} 2 and 3.} (\cite{pyautogui})
% subsection shell script
\subsection{shell script}\label{sec:shell_script}
A \gls{shellscript} is a plain text file of commands that is executed on a computer terminal, also known as a shell. Linux (BaSH \cite{bash}, zsh \cite{zsh}), Mac (zsh \cite{zsh}), and \Gls{windowspowershell} (\cite{windowspowershell}) can easily execute \glspl{shellscript}. \Gls{windowspowershell} offers similar functionality and has its own syntax for the commands.
% subsection scrapy
\subsection{Scrapy + Beautiful Soup + Requests + urllib}\label{sec:scrapy}
\enquote{\Gls{scrapy} is a fast high-level web crawling and \gls{webscraping} framework, used to crawl websites and extract structured data from their pages. It can be used for a wide range of purposes, from data mining to monitoring and automated testing.} (\cite{scrapy}) \Gls{beautifulsoup} (\cite{beautifulsoup}) parses HTML and XML documents to create a tree-like representation of the document structure and extract data. \enquote{\Gls{requests} is a simple, yet elegant, HTTP library. \Gls{requests} allows you to send HTTP/1.1 requests extremely easily.} (\cite{requests}) \enquote{\gls{urllib} is a package that collects several modules for working with URLs.} (\cite{urllib})
% subsection openpyxl + pandas
\subsection{openpyxl + pandas}\label{sec:openpyxl_pandas}
\enquote{\gls{openpyxl} is a \Gls{python} library to read/write Excel 2010 xlsx/xlsm/xltx/xltm files.} (\cite{openpyxl})  \enquote{\gls{pandas} is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the \Gls{python} programming language.} (\cite{pandas})
% subsection pytesseract opencv
\subsection{Python Tesseract + OpenCV}\label{sec:pytesseract_opencv}
\enquote{\Gls{tesseract} is an optical character recognition engine (libtesseract) and a command line program (tesseract).} (\cite{tesseract}) \enquote{\Gls{pytesseract} is a wrapper for \Gls{tesseract}. It is also useful as a stand-alone invocation script to \Gls{tesseract} image types supported by the Pillow and Leptonica imaging libraries, including jpeg, png, gif, bmp, tiff, and others. Additionally, if used as a script, \Gls{pytesseract} will print the recognized text instead of writing it to a file.} (\cite{pytesseract}) \enquote{OpenCV (Open Source Computer Vision Library: http://opencv.org) is an open-source library that includes several hundreds of computer vision algorithms.} (\cite{opencv})
% section examples
\section{Examples}\label{sec:examples}
% subsection automate sending an email
\subsection{Automate sending an email (PyAutoGUI)}\label{sec:automate_sending_an_email}
There are times when one needs to send a recurring email to a group of people and include multiple attachments. Preparing and sending an email takes time, ensuring you have an up-to-date list of recipients, and enclosing the attachments. This can easily be done with \Gls{pyautogui} (\cite{pyautogui}).
\begin{footnotesize}
\begin{minted}{python}
#! /usr/bin/env python3
'''
Send an Outlook email, multiple recipients, multiple attachments, body text.
Execute:
- revise message, emails, attachments, directory as required
- in a terminal: python -m email_demo.py
- add to Windows Task Scheduler or Linux cron for timed execution
'''

import sys


def excepthook(*args, **kwargs):
    """
    Diagnose missing packages.
    This is used because the main script may be executed by Task Scheduler
    and prevents an error from closing a terminal.
    """
    print(*args, kwargs)
    from traceback import print_tb
    print_tb(args[2])
    input('Press <Enter> to exit.')


sys.excepthook = excepthook


from pathlib import Path
import time

import pyautogui as pyg
import datasense as ds


def main():
    message = [
        'This is the first line of text with a line break.\n\n'
        'This is the second line, first sentence. '
        'This is the second sentence.\n\n'
        '<user>'
    ]
    emails = ['gillespilon13@gmail.com']
    attachments = ['presentation.pptx', 'data.csv']
    directory = '~/<user>/documents/'
    header_title = 'email demonstration'
    output_url = 'email_demo.html'
    header_id = 'email_demo'
    original_stdout = ds.html_begin(
        output_url=output_url,
        header_title=header_title,
        header_id=header_id
    )
    ds.script_summary(
        script_path=Path(__file__),
        action='started at'
    )
    start_time = time.perf_counter()
    path_files = Path(Path.home().resolve(), directory)
    # create an email window in Outlook
    pyg.hotkey('win')
    time.sleep(1)
    pyg.write('out')
    time.sleep(1)
    pyg.hotkey('enter')
    time.sleep(5)
    pyg.hotkey('ctrl', 'n')
    time.sleep(1)
    for email in emails:
        print(email)
        print('tab')
    for email in emails:
        pyg.write(email)
        pyg.press('tab')
    pyg.press('tab')
    pyg.write('Test of PyAutoGUI attachment')
    pyg.hotkey('enter')
    pyg.hotkey('enter')
    time.sleep(0.5)
    for item in message:
        time.sleep(0.5)
        pyg.write(item)
    time.sleep(0.5)
    for attachment in attachments:
        print('TEST START')
        print(path_files)
        print(attachment)
        path = Path(path_files, attachment)
        print(path)
        print('TEST END')
        print()
        pyg.keyDown('alt')
        pyg.press('6')
        pyg.keyUp('alt')
        time.sleep(0.5)
        pyg.keyDown('alt')
        pyg.press('n')
        pyg.keyUp('alt')
        time.sleep(0.5)
        pyg.write(str(path))
        pyg.keyDown('alt')
        pyg.press('s')
        pyg.keyUp('alt')
    pyg.keyDown('alt')
    pyg.press('s')
    pyg.keyUp('alt')
    print('emails sent to:')
    print()
    ds.print_list_by_item(list=emails)
    print()
    stop_time = time.perf_counter()
    ds.script_summary(
        script_path=Path(__file__),
        action='finished at'
    )
    ds.report_summary(
        start_time=start_time,
        stop_time=stop_time
    )
    ds.html_end(
        original_stdout=original_stdout,
        output_url=output_url
    )


if __name__ == '__main__':
    main()
\end{minted}
\end{footnotesize}
% subsection automate updating repositories
\subsection{Automate updating repositories (shell script)}\label{sec:automate_updating_repositories}
A workgroup often requires access to one or more code repositories, even if they are users and not developers of code. There are several powerful code repositories [\Gls{github} (\cite{github}), \Gls{gitlab} (\cite{gitlab}), \gls{heptapodfoss} (\cite{heptapodfoss})] to store and access code. This can easily be done with a \gls{shellscript}. The following script works with BaSH (\cite{bash}) and zsh (\cite{zsh}).
\begin{footnotesize}
\begin{minted}{python}
#! /bin/sh
# update clones of GitHub repositories
# in a terminal: sh update_repositories.sh
echo
# change path to home directory
cd ~/
# update datasense
echo 'update datasense repository'
echo
pip install --user --upgrade -e "git+https://github.com/gillespilon/datasense#egg=datasense"
# update packages
echo
echo 'update required Python packages'
echo
pip install --user -U pandoc pyautogui pyarrow tabulate
# git pull gitlab_code
echo
echo 'git pull on GitLab code repository'
echo
cd Documents/gitlab_code
git pull
# git pull gitlab_job_aids
echo
echo 'git pull on GitLab job aids repository'
echo
cd ../gitlab_job_aids
git pull
# convert mkd -> html
cd fol
./update_html.sh
\end{minted}
\end{footnotesize}
% subsection automate sap report
\subsection{Automate SAP report (PyAutoGUI)}\label{sec:automate_sap_report}
An \Gls{sap} user will be granted access to various reports and portions of the \Gls{sap} warehouse. If a user needs data extracted from a report, and is not trained in how to create one, it often takes a long time to get a report written and made available in the user's profile. An alternative is to mimic the mouse and keyboard movements of manually access an existing report to extract and compile the data required. The following \Gls{python} script logs into \Gls{sap}, navigates to a specific report, extracts the data for multiple prior months, and saves the data in csv files in a particular directory for further processing. This script is easily scheduled with \Gls{windowstaskscheduler}.
\begin{footnotesize}
\begin{minted}{python}
#! /usr/bin/env python3
'''
Execute SAP spend report for a number of prior calendar months.
In a terminal: python -m sap_spend_report.py
'''

import sys


def excepthook(*args, **kwargs):
    """
    Diagnose missing packages.
    This is used because the main script may be executed by Task Scheduler
    and prevents an error from closing a terminal.
    """
    print(*args, kwargs)
    from traceback import print_tb
    print_tb(args[2])
    input('Press <Enter> to exit.')


sys.excepthook = excepthook


from datetime import datetime
from pathlib import Path
import subprocess
import time

from dateutil.relativedelta import relativedelta
import pyautogui as pyg
import datasense as ds


def main():
    # define parameters
    start_time_0 = time.perf_counter()
    sap_process = r"C:\Program Files (x86)\SAP\FrontEnd\SapGui\saplogon.exe"
    directory_files = 'supplier_risk/supplier_risk_data_input'
    directory_gitlab_code = 'Documents/gitlab_code'
    output_url = 'sap_spend_report.html'
    path_home = Path.home().resolve()
    header_title = 'SAP spend report'
    header_id = 'sap-spend-report'
    number_months_prior_start = 1
    number_months_prior_end = 1
    original_stdout = ds.html_begin(
        output_url=output_url,
        header_title=header_title,
        header_id=header_id
    )
    ds.script_summary(
        script_path=Path(__file__),
        action='started at'
    )
    stop_time_0 = time.perf_counter()
    elapsed_time = stop_time_0 - start_time_0
    print(
        'Set-up time:',
        round(elapsed_time, 3),
        's'
    )
    print()
    # create list of dates
    dates = [
            f"{(datetime.today() + relativedelta(months=-x)):%Y%m}"
        for x in range(number_months_prior_start, number_months_prior_end + 1)
    ]
    # use PyAutoGUI to create csv file from
    # SAP > BWP > Global Vendor Detail Spend Report_New
    for date in dates:
        path_file_name = Path(date + '_vendor_data.csv')
        path_output_file = Path(
            path_home, directory_gitlab_code, directory_files, path_file_name
        )
        print('Started:', path_output_file)
        # quit SAP and Excel
        ds.quit_sap_excel()
        start_time_1 = time.perf_counter()
        # open SAP > BWP report
        subprocess.Popen(sap_process)
        time.sleep(20)
        pyg.write('09')
        pyg.keyDown('enter')
        time.sleep(20)
        pyg.hotkey('ctrl', 'f')
        time.sleep(5)
        pyg.write('global vendor detail spend report_new')
        pyg.keyDown('enter')
        time.sleep(5)
        pyg.hotkey('f2')
        # fill fields in report
        # this is critical to allow SAP time
        time.sleep(90)
        for x in range(0, 9):
            pyg.hotkey('tab')
        pyg.write(date)
        for x in range(0, 2):
            pyg.hotkey('tab')
        pyg.write(date)
        pyg.keyDown('enter')
        # wait for Excel workbook to open
        # this is critical to allow SAP time
        time.sleep(90)
        # select and copy data
        pyg.hotkey('win', 'up')
        time.sleep(2)
        pyg.hotkey('ctrl', 'a')
        time.sleep(2)
        pyg.keyDown('alt')
        pyg.press('h')
        pyg.press('c')
        pyg.press('c')
        pyg.keyUp('alt')
        time.sleep(2)
        # paste data in blank workbook
        pyg.keyDown('alt')
        pyg.press('f')
        time.sleep(1)
        pyg.press('n')
        time.sleep(1)
        pyg.press('l')
        pyg.keyUp('alt')
        time.sleep(1)
        pyg.press('left')
        pyg.keyDown('alt')
        pyg.press('h')
        pyg.press('v')
        pyg.press('v')
        pyg.keyUp('alt')
        time.sleep(1)
        pyg.press('up')
        time.sleep(1)
        # delete row above labels
        pyg.keyDown('alt')
        pyg.press('h')
        pyg.press('d')
        pyg.press('r')
        pyg.keyUp('alt')
        time.sleep(1)
        # save as csv file
        pyg.keyDown('alt')
        pyg.press('f')
        time.sleep(1)
        pyg.press('a')
        time.sleep(1)
        pyg.press('c')
        time.sleep(1)
        pyg.press('1')
        time.sleep(1)
        pyg.keyUp('alt')
        pyg.write(str(path_output_file))
        time.sleep(1)
        pyg.hotkey('tab')
        time.sleep(1)
        pyg.press('down')
        time.sleep(1)
        pyg.press('w')
        time.sleep(1)
        pyg.press('up')
        time.sleep(1)
        pyg.press('up')
        time.sleep(1)
        pyg.press('up')
        time.sleep(1)
        pyg.keyDown('enter')
        time.sleep(1)
        pyg.keyDown('alt')
        pyg.press('s')
        time.sleep(1)
        pyg.press('y')
        time.sleep(1)
        pyg.keyUp('alt')
        print('Created:', path_output_file)
        print(f'Size   : {path_output_file.stat().st_size/1024:.0f} KiB')
        stop_time_1 = time.perf_counter()
        elapsed_time = stop_time_1 - start_time_1
        print(
            'Execution time:',
            round(elapsed_time, 3),
            's'
        )
        print()
    # quit SAP and Excel
    ds.quit_sap_excel()
    stop_time_2 = time.perf_counter()
    ds.script_summary(
        script_path=Path(__file__),
        action='finished at'
    )
    ds.report_summary(
        start_time=start_time_0,
        stop_time=stop_time_2
    )
    ds.html_end(
        original_stdout=original_stdout,
        output_url=output_url
    )


if __name__ == '__main__':
    main()
\end{minted}
\end{footnotesize}
% subsection automate data extract power bi
\subsection{Automate data extraction from Power BI (PyAutoGUI)}\label{sec:automate_data_extraction_from_power_bi}
A \Gls{windowspowerbi} (\cite{windowspowerbi}) user does not normally have access to the data behind the reports. If a user needs data extracted from a report, it often takes a long time to get a report written and made available in the \Gls{windowspowerbi} report. An alternative is to mimic the mouse and keyboard movements of manually access an existing report to extract and compile the data required. The following \Gls{python} script creates a csv file from a \Gls{windowspowerbi} dashboard. This script is easily scheduled with \Gls{windowstaskscheduler}.
\begin{footnotesize}
\begin{minted}{python}
#! /usr/bin/env python3
'''
Create a csv file from a SharePoint dashboard.
'''

import sys


def excepthook(*args, **kwargs):
    """
    Diagnose missing packages.
    This is used because the main script may be executed by Task Scheduler
    and prevents an error from closing a terminal.
    """
    print(*args, kwargs)
    from traceback import print_tb
    print_tb(args[2])
    input('Press <Enter> to exit.')


sys.excepthook = excepthook


from typing import List
from pathlib import Path
import webbrowser
import time

import pyautogui as pyg
import datasense as ds
import pandas as pd


def main():
    # define parameters
    reorder_columns = [
        'Vendor', 'Vendor_Name', 'Notifications', 'Material_Group_Number',
        'Months'
    ]
    dashboard_url = (
        'https://app.powerbi.com/groups/me/reports/'
        '8daf409d-c0a7-40a4-b979-4cc28bbf363b/ReportSection?'
        'ctid=101ce67d-13f2-447a-bb65-0989b89dfdb4'
    )
    rename_columns_initially = {
        'Supplier': 'Vendor',
        'Sum of Number of notifications': 'Notifications'
    }
    path_final_file = Path('qn_notifications.csv')
    output_url = 'report.html'
    header_title = 'report'
    path_files = Path('../../Downloads')
    header_id = 'report'
    rename_columns_finally = {
        'VN': 'Vendor',
        'VT': 'Vendor_Name'
    }
    material_groups = [
        '101 - Plastic Resins',
        '102 - Metal Raw Materials',
        '103 - Die Castings',
        '201 - Non-Metallic Parts',
        '202 - Metal & Mech Parts',
        '203 - Wire & Cable',
        '204 - Conn Assy&Subcon Mfg',
        # '205 - Resale Tools & Press'
        '206 - Electronic Comp',
        '207 - Electronic Assy',
        '208 - Competitor Products',
        '209 - PCB, FPC and FFC',
        '301 - Packaging'
    ]
    extensions = ['.xlsx', '.XLSX']
    months = [12, 6]
    start_time = time.perf_counter()
    material_group_number = [int(x[:3]) for x in material_groups]
    number_files_created = len(months) * len(material_groups)
    combinations = [
        (mg, month) for mg in material_group_number for month in months
    ]
    original_stdout = ds.html_begin(
        output_url=output_url,
        header_title=header_title,
        header_id=header_id
    )
    ds.script_summary(
        script_path=Path(__file__),
        action='started at'
    )
    # open Dashboard
    webbrowser.open(url=dashboard_url)
    time.sleep(30)
    # create individual files
    for mg in material_groups:
        material_group(material_group=mg)
        for month in months:
            change_date(month=month)
            export_file()
            time.sleep(2)
        deselect_material_group()
    # create list of paths, sorted newest to oldest modification time
    files_in_downloads = sorted(
        ds.list_files(
            directory=path_files,
            patterns=extensions
        ),
        key=ds.get_mtime,
        reverse=False
    )[-number_files_created:]
    print_file_size(files=files_in_downloads)
    # create final dataframe
    dfs = pd.DataFrame()
    for file, (x, y) in zip(files_in_downloads, combinations):
        # create individual DataFrames
        df = ds.read_file(
            file_name=file,
            skiprows=[0, 1]
        ).rename(columns=rename_columns_initially)
        df['VN'] = df['Vendor'].str[:6]
        df['VT'] = df['Vendor'].str[9:]
        df['Material_Group_Number'] = x
        df['Months'] = y
        df = df.drop(columns=['Vendor'])
        df = df.rename(columns=rename_columns_finally)
        df = df[reorder_columns]
        dfs = dfs.append(df)
    # remove rows where Vendor contains '-'
    dfs = dfs.loc[~dfs['Vendor'].str.contains(pat='-', na=False)]
    # create final file
    ds.save_file(
        df=dfs,
        file_name=Path(path_final_file)
    )
    # delete individual files
    for file in files_in_downloads:
        Path(file).unlink(missing_ok=True)
    stop_time = time.perf_counter()
    ds.script_summary(
        script_path=Path(__file__),
        action='finished at'
    )
    ds.report_summary(
        start_time=start_time,
        stop_time=stop_time
    )
    ds.html_end(
        original_stdout=original_stdout,
        output_url=output_url
    )


def change_date(
    *,
    month: int
) -> None:
    '''
    Change date and format.
    '''
    # change date
    pyg.moveTo(460, 335)
    time.sleep(2)
    pyg.doubleClick()
    time.sleep(2)
    pyg.write(str(month))
    time.sleep(2)
    # change to calendar months
    pyg.hotkey('tab')
    pyg.press('down')
    for x in range(1, 9):
        pyg.press('up')
        time.sleep(0.2)
    for x in range(1, 6):
        pyg.press('down')
        time.sleep(0.2)
    pyg.keyDown('enter')
    time.sleep(2)


def material_group(
    *,
    material_group: str
) -> None:
    '''
    Select the material group.
    '''
    pyg.moveTo(420, 755)
    time.sleep(2)
    pyg.click()
    pyg.moveTo(420, 510)
    time.sleep(2)
    pyg.click()
    pyg.write(material_group)
    time.sleep(2)
    pyg.moveTo(420, 535)
    time.sleep(2)
    pyg.click()
    time.sleep(2)


def deselect_material_group() -> None:
    '''
    Select all material groups available.
    '''
    pyg.moveTo(420, 755)
    time.sleep(2)
    pyg.click()
    pyg.moveTo(420, 510)
    time.sleep(2)
    pyg.click()
    time.sleep(2)
    pyg.hotkey('ctrl', 'a', 'backspace')
    time.sleep(2)
    pyg.moveTo(420, 540)
    time.sleep(2)
    pyg.click()
    time.sleep(2)
    pyg.click()
    time.sleep(2)
    pyg.moveTo(250, 755)
    pyg.click()
    time.sleep(2)


def export_file() -> None:
    '''
    Export the data.
    '''
    # export file
    pyg.moveTo(1150, 645)
    time.sleep(2)
    pyg.click()
    pyg.moveTo(1150, 610)
    time.sleep(2)
    pyg.click()
    pyg.moveTo(1230, 725)
    time.sleep(2)
    pyg.click()
    pyg.moveTo(1200, 915)
    time.sleep(2)
    pyg.click()
    pyg.moveTo(1840, 250)
    time.sleep(2)
    pyg.click()
    # close downloads bar
    pyg.moveTo(1890, 1035)
    time.sleep(2)
    pyg.click()
    time.sleep(2)


def print_file_size(
    *,
    files: List[str]
) -> None:
    '''
    Print the file size for all individual files created.
    '''
    for file in files:
        print('Created:', file)
        print(f'Size   : {file.stat().st_size/1024:.0f} KiB')
        print()


if __name__ == '__main__':
    main()

\end{minted}
\end{footnotesize}
% subsection automate data extract power bi
\subsection{Automate data extraction from Wikipedia table (pandas)}\label{sec:automate_data_extraction_from_wikipedia_table}
There are many libraries to perform \gls{webscraping}. The best one is \Gls{scrapy} (\cite{scrapy}). However, for many \gls{webscraping} tasks one might only need the \gls{pandas} library (\cite{pandas}) which has several methods (pd.read\_html, df.to\_html, pd.read\_xml, df.to\_xml).
\begin{footnotesize}
\begin{minted}{python}
#! /usr/bin/env python3
"""
Get country codes, names, domains from Wikipedia table and create csv file.
Execute in a terminal: python -m country_codes_names_domains.py
"""

import sys


def excepthook(*args, **kwargs):
    """
    Diagnose missing packages.
    This is used because the main script may be executed by Task Scheduler
    and prevents an error from closing a terminal.
    """
    print(*args, kwargs)
    from traceback import print_tb

    print_tb(args[2])
    input("Press <Enter> to exit.")


sys.excepthook = excepthook


from pathlib import Path
from os import chdir
import time

import datasense as ds
import pandas as pd


def main():
    # required for cron
    chdir(Path(__file__).parent.resolve())
    # define parameters
    start_time = time.perf_counter()
    wiki_url = "https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2"
    output_url = "country_codes_names_domains.html"
    header_title = "Country codes, names, domains"
    column_labels = ["Code", "Country", "Domain"]
    header_id = "country-codes-names-domains"
    path_file_out = Path("country_codes.csv")
    drop_columns = ["Year", "Notes"]
    original_stdout = ds.html_begin(
        output_url=output_url, header_title=header_title, header_id=header_id
    )
    ds.script_summary(script_path=Path(__file__), action="started at")
    # create DataFrame from Wikipedia table
    data = (
        pd.DataFrame(
            data=pd.read_html(
                io=wiki_url,
                attrs={"class": "wikitable sortable"},
                keep_default_na=False,
            )[0]
        )
        .drop(labels=drop_columns, axis="columns")
        .set_axis(labels=column_labels, axis="columns")
    )
    # save DataFrame as csv file
    ds.save_file(df=data, file_name=path_file_out)
    print(data)
    print()
    stop_time = time.perf_counter()
    ds.script_summary(script_path=Path(__file__), action="finished at")
    ds.report_summary(
        start_time=start_time,
        stop_time=stop_time,
        save_file_names=path_file_out.resolve(),
    )
    ds.html_end(original_stdout=original_stdout, output_url=output_url)


if __name__ == "__main__":
    main()
\end{minted}
\end{footnotesize}
\newpage
% section datasense
\section{datasense}\label{sec:datasense}
\href{https://github.com/gillespilon/datasense}{datasense} (\cite{datasense}) is a \Gls{python} package for statistical, graphical, and predictive analysis. Instructions on how to use datasense are provided in relevant sections of this document. To use datasense, install a \Gls{python} distribution appropriate to your operating system. Then install datasense following the instructions  at \href{https://github.com/gillespilon/datasense}{https://github.com/gillespilon/datasense}.
Instructions on how to use datasense are provided in relevant sections of this document.
Full documentation is available at \href{https://datasense.readthedocs.io/en/latest/}{https://datasense.readthedocs.io/en/latest/}
\newpage
% section abbreviations
\printunsrtglossary[type={abbreviations}]
\newpage
% section glossary
\printunsrtglossary[style={indexgroup}]
\newpage
% section references
\section{References}\label{sec:references}
\printbibliography[heading=none]
\end{document}
